# 知网文献自动化下载 - 完整使用指南

**文档版本**: v1.0  
**创建日期**: 2025-10-19  
**适用场景**: 使用Chrome DevTools MCP批量下载CNKI学术文献

---

## 📋 目录

1. [快速开始](#快速开始)
2. [当前项目进度](#当前项目进度)
3. [完整操作流程](#完整操作流程)
4. [如何复用此经验](#如何复用此经验)
5. [常见问题解决](#常见问题解决)
6. [附录：代码模板](#附录代码模板)

---

## 🚀 快速开始

### 前置准备

**环境要求**:
- ✅ Chrome浏览器 + Chrome DevTools MCP已配置
- ✅ Python 3.x 环境
- ✅ 知网账号（通过机构登录）
- ✅ 充足的磁盘空间

**必备文件**:
```
项目根目录/
├── Chrome_DevTools_MCP_自动化下载经验总结.md  # 技术文档
├── 文献下载进度报告_2025-10-19.md           # 进度报告
├── move_recent_pdfs.py                        # 文件移动脚本
├── check_all_progress.py                      # 进度检查脚本
└── download_progress.json                     # 进度数据
```

### 5分钟快速上手

```bash
# 1. 检查当前进度
python check_all_progress.py

# 2. 启动Chrome并连接MCP（在Cursor中使用Chrome DevTools MCP工具）

# 3. 告诉AI：
"使用Chrome DevTools MCP下载知网第XX-XX篇文献到文件夹XX-XX/"

# 4. 下载完成后移动文件
python move_recent_pdfs.py

# 5. 再次检查进度
python check_all_progress.py
```

---

## 📊 当前项目进度

### 总体情况

| 指标 | 数值 |
|------|------|
| **目标总数** | 200篇 |
| **已完成** | 173篇 |
| **完成率** | 86.5% |
| **待完成** | 27篇 |

### 详细分组状态

| 文章范围 | 文件夹 | 状态 | 已下载 | 缺失 | 完成率 |
|---------|--------|------|--------|------|--------|
| 1-20 | 1-20 | ✅ 完成 | 20 | 0 | 100% |
| 21-40 | 21-40 | ⚠️ 未完成 | 16 | 4 | 80% |
| 41-60 | 41-60 | ⚠️ 未完成 | 19 | 1 | 95% |
| 61-80 | 61-80 | ⚠️ 未完成 | 19 | 1 | 95% |
| 81-100 | 81-100 | ✅ 完成 | 20 | 0 | 100% |
| 101-120 | 101-120 | ✅ 完成 | 20 | 0 | 100% |
| 121-140 | 121-140 | ⚠️ 未完成 | 15 | 5 | 75% |
| 141-160 | 141-160 | ✅ 完成 | 20 | 0 | 100% |
| 161-180 | 161-180 | ⚠️ 未完成 | 11 | 9 | 55% |
| 181-200 | 181-200 | ⚠️ 未完成 | 13 | 7 | 65% |

### 优先级排序

**下次下载顺序（按缺失数量）**:
1. 🔴 **第161-180篇** - 缺失9篇（最优先）
2. 🟠 **第181-200篇** - 缺失7篇
3. 🟡 **第121-140篇** - 缺失5篇
4. 🟢 **第21-40篇** - 缺失4篇
5. 🔵 **第41-60篇** - 缺失1篇
6. 🟣 **第61-80篇** - 缺失1篇

---

## 📖 完整操作流程

### 步骤1: 检查进度并确定下载目标

```bash
# 运行进度检查脚本
python check_all_progress.py
```

**输出示例**:
```
[INCOMPLETE] 161-180      | 11/20 | 55.0% | Missing:  9
[INCOMPLETE] 181-200      | 13/20 | 65.0% | Missing:  7
```

📌 **决定**: 先下载161-180篇（缺失最多）

### 步骤2: 启动浏览器并导航

**在Cursor中对AI说**:
```
打开浏览器，访问知网搜索结果页面
```

**预期**: 浏览器打开知网搜索页面，显示"钱学森"作者的搜索结果

### 步骤3: 翻页到目标位置

**计算目标页码**:
- 每页20篇文献
- 第161-180篇 → 第9页 (161÷20 = 8.05，向上取整为第9页)
- 第181-200篇 → 第10页

**对AI说**:
```
请手动翻到第9页（第161-180篇）
```

**或者让用户自己操作**:
- 在浏览器中点击底部的页码"9"
- 完成后告诉AI："翻页完成"

### 步骤4: 批量下载

**对AI说**:
```
批量下载当前页面的所有20篇文献
```

**AI会执行**:
1. 提取当前页的20个文献链接
2. 批量打开20个详情页
3. 逐个切换页面并点击"PDF下载"按钮

**预期时间**: 5-10分钟（取决于网速和知网响应）

### 步骤5: 处理频率限制

**如果遇到验证页面**:
- ⏸️ 暂停当前批次
- ⏰ 等待5-10分钟
- 🔄 继续剩余下载

**对AI说**:
```
遇到验证页面了，我们暂停10分钟后继续
```

### 步骤6: 移动已下载文件

**下载完成后执行**:
```bash
python move_recent_pdfs.py
```

**脚本会**:
- 🔍 查找Downloads文件夹中最近30分钟的PDF文件
- 📦 自动移动到目标文件夹（默认181-200/）
- ✅ 显示移动结果

### 步骤7: 验证结果

```bash
python check_all_progress.py
```

**检查**:
- 161-180文件夹是否增加了文件
- 缺失数量是否减少
- 整体完成率是否提升

### 步骤8: 继续下一批次

如果还有未完成的，重复步骤2-7。

---

## 🔄 如何复用此经验

### 场景1: 下载其他作者的文献

**适用**: 需要下载另一位作者（如"李四"）的文献

**复用步骤**:

1. **修改搜索条件**:
```
在知网搜索"作者：李四"，获取搜索结果URL
```

2. **创建新的文件夹结构**:
```bash
mkdir "# 系统科学资源\文献PDF\李四-作者-相关资料"
mkdir "# 系统科学资源\文献PDF\李四-作者-相关资料\1-20"
# ... 创建其他子文件夹
```

3. **调整脚本中的路径**:
```python
# 在 move_recent_pdfs.py 中修改
base_target = Path(r'# 系统科学资源\文献PDF\李四-作者-相关资料')
```

4. **执行相同的下载流程**:
   - 按照步骤1-8执行
   - 使用相同的批量下载策略

### 场景2: 下载不同数据库的文献

**适用**: 万方数据库、维普数据库等

**需要调整的地方**:

1. **页面选择器**:
```javascript
// 知网使用
const rows = document.querySelectorAll('table.result-table-list tbody tr');
const titleLink = rows[i].querySelector('a.fz14');

// 万方可能是（需要实际检查）
const rows = document.querySelectorAll('.result-item');
const titleLink = rows[i].querySelector('.title-link');
```

2. **下载按钮定位**:
```javascript
// 根据目标网站的实际HTML结构调整
// 使用take_snapshot查看页面元素的uid
```

3. **其他保持不变**:
   - 批量打开策略相同
   - 文件移动脚本相同
   - 进度检查逻辑相同

### 场景3: 下载特定主题的文献

**适用**: 按主题关键词（如"系统科学"）批量下载

**调整方案**:

1. **搜索策略**:
```
主题："系统科学" AND 作者："钱学森"
```

2. **文件夹命名**:
```
系统科学-主题-钱学森作者/
├── 1-20/
├── 21-40/
└── ...
```

3. **其余流程完全相同**

### 场景4: 下载特定期刊的文献

**适用**: 下载某期刊（如《系统工程理论与实践》）的所有文献

**调整方案**:

1. **搜索条件**:
```
来源：《系统工程理论与实践》
```

2. **按年份或期数组织**:
```
系统工程理论与实践-期刊/
├── 2020年/
├── 2021年/
└── 2022年/
```

3. **脚本调整**:
```python
# 按年份分组而非固定20篇分组
groups = [
    ('2020', '2020年'),
    ('2021', '2021年'),
    ('2022', '2022年')
]
```

---

## ❓ 常见问题解决

### 问题1: 下载速度慢或频繁出现验证码

**原因**: 知网的反爬虫机制

**解决方案**:
```
策略A: 降低并发数
- 一次只打开10个详情页（而非20个）
- 每5个下载后暂停1-2分钟

策略B: 错峰下载
- 选择凌晨或深夜时段（用户较少）
- 避开工作日白天（高峰期）

策略C: 分散IP
- 使用机构不同的网络出口
- 或使用VPN（如果允许）
```

### 问题2: 文件移动失败（中文路径问题）

**现象**: PowerShell报错或文件名乱码

**解决方案**:
```python
# ✅ 始终使用Python脚本移动文件
# ❌ 不要用PowerShell的Move-Item或CMD的move命令

# 确保使用原始字符串和正确的中文括号
target = Path(r'路径（中文括号）')  # ✅
target = Path(r'路径(英文括号)')   # ❌ 如果文件夹用的是中文括号
```

### 问题3: 页面无法翻到指定页码

**现象**: URL参数`curpage=10`不生效

**解决方案**:
```javascript
// 方法1: JavaScript循环点击（AI可自动执行）
for (let i = 0; i < 9; i++) {
  document.querySelector('a:contains("下一页")').click();
  await new Promise(r => setTimeout(r, 2000));
}

// 方法2: 手动点击（最可靠）
告诉AI："我已经手动翻到第10页了"
```

### 问题4: 下载的PDF数量对不上

**诊断步骤**:

```bash
# 1. 检查Downloads文件夹
ls ~/Downloads/*.pdf | wc -l

# 2. 检查目标文件夹
python check_all_progress.py

# 3. 查看浏览器下载历史
# Chrome -> 下载 -> 查看最近下载的文件
```

**可能原因**:
- ❌ 某些文献没有PDF（只有CAJ格式）
- ❌ 下载被验证码中断
- ❌ 文件还在下载中（未完成）

**解决**:
```bash
# 等待所有下载完成后再移动文件
# 检查Downloads文件夹确认文件完整性
```

### 问题5: Chrome DevTools MCP连接失败

**现象**: `list_pages()`返回"未连接"错误

**解决方案**:
```bash
# 1. 关闭所有Chrome进程
taskkill /F /IM chrome.exe

# 2. 启动Chrome调试模式
start chrome --remote-debugging-port=9222 --user-data-dir="C:\chrome-debug"

# 3. 在Cursor中重新连接MCP

# 4. 测试连接
对AI说："list_pages 测试连接"
```

---

## 📦 附录：代码模板

### 模板1: 批量下载主函数

```python
def batch_download(start_article, end_article, target_folder):
    """
    批量下载知网文献
    
    使用方法:
        batch_download(161, 180, '161-180')
    
    Args:
        start_article: 起始文章编号
        end_article: 结束文章编号
        target_folder: 目标文件夹名称
    """
    # 步骤详见"完整操作流程"
    pass
```

### 模板2: 快速移动脚本

```python
# move_to_folder.py
import sys
from pathlib import Path
import shutil, time, os

def move_recent_pdfs(target_folder_name, minutes=30):
    downloads = Path(os.environ['USERPROFILE']) / 'Downloads'
    base = Path(r'# 系统科学资源\文献PDF\钱学森-作者-相关资料（总库299）')
    target = base / target_folder_name
    target.mkdir(parents=True, exist_ok=True)
    
    cutoff = time.time() - (minutes * 60)
    moved = 0
    
    for pdf in downloads.glob('*.pdf'):
        if pdf.stat().st_mtime > cutoff:
            shutil.move(str(pdf), str(target / pdf.name))
            moved += 1
            print(f'✓ {pdf.name}')
    
    print(f'\n已移动 {moved} 个文件到 {target_folder_name}/')
    return moved

if __name__ == '__main__':
    if len(sys.argv) > 1:
        folder = sys.argv[1]
    else:
        folder = '181-200'  # 默认文件夹
    
    move_recent_pdfs(folder)
```

**使用方法**:
```bash
# 移动到默认文件夹（181-200）
python move_to_folder.py

# 移动到指定文件夹
python move_to_folder.py 161-180
```

### 模板3: 快速进度检查

```python
# quick_check.py
from pathlib import Path

base = Path(r'# 系统科学资源\文献PDF\钱学森-作者-相关资料（总库299）')
folders = ['1-20', '21-40', '41-60', '61-80', '81-100',
           '101-120', '121-140', '141-160', '161-180', '181-200']

print("快速进度检查")
print("=" * 50)

total = 0
for folder in folders:
    path = base / folder
    if path.exists():
        count = len(list(path.glob('*.pdf')))
        total += count
        status = '✅' if count == 20 else f'⚠️ 缺{20-count}'
        print(f"{folder:12s}: {count:2d}/20  {status}")
    else:
        print(f"{folder:12s}: 文件夹不存在")

print("=" * 50)
print(f"总计: {total}/200 ({total/2:.1f}%)")
```

**使用方法**:
```bash
python quick_check.py
```

### 模板4: AI提示词模板

**下载特定范围文献**:
```
请使用Chrome DevTools MCP下载知网第161-180篇文献：
1. 当前应该在第9页（第161-180篇）
2. 批量打开所有20个详情页
3. 逐个点击PDF下载按钮
4. 使用分批策略，每5个暂停1分钟
```

**检查下载进度**:
```
请运行check_all_progress.py检查当前下载进度
并告诉我：
1. 总体完成率
2. 哪些分组还未完成
3. 建议下一步下载哪个分组
```

**移动文件**:
```
请运行Python脚本将Downloads文件夹中最近下载的PDF文件
移动到"161-180"文件夹，并报告移动了多少个文件
```

---

## 🎯 实战案例

### 案例1: 完成161-180篇的下载（缺9篇）

**目标**: 将161-180文件夹从11篇补充到20篇

**完整对话流程**:

```
用户: "打开浏览器，访问知网搜索结果"
AI: [打开浏览器并访问知网]

用户: "翻到第9页"
AI: [尝试翻页，可能需要手动]

用户: "我已经手动翻到第9页了"
AI: [获取页面快照，确认在第9页]

用户: "批量下载这一页的所有文献"
AI: [执行批量下载流程]
    1. 提取20个链接
    2. 打开20个详情页
    3. 逐个下载PDF
    
[10分钟后]

AI: "已完成下载，部分文献可能因验证码未成功"

用户: "移动文件到161-180文件夹"
AI: [运行move_recent_pdfs.py]
    "已移动 8 个文件"

用户: "检查进度"
AI: [运行check_all_progress.py]
    "161-180: 19/20 (95%)"

用户: "还差1篇，继续下载"
AI: [重复上述流程，只针对缺失的1篇]
```

**预计时间**: 20-30分钟（包括验证码等待）

### 案例2: 完成所有剩余27篇

**策略**: 分3个会话完成

**会话1**（今天）:
- 目标: 161-180篇（缺9篇）+ 181-200篇（缺7篇）
- 预计: 下载15-16篇

**会话2**（明天）:
- 目标: 121-140篇（缺5篇）+ 21-40篇（缺4篇）
- 预计: 下载8-9篇

**会话3**（后天）:
- 目标: 41-60篇（缺1篇）+ 61-80篇（缺1篇）+ 补漏
- 预计: 完成全部

---

## ✅ 使用检查清单

### 开始前检查
- [ ] Chrome DevTools MCP已连接（运行`list_pages`测试）
- [ ] 知网账号已登录
- [ ] 已运行`check_all_progress.py`了解当前进度
- [ ] 确定本次下载的目标范围

### 下载过程中
- [ ] 确认页码正确（对应文章范围）
- [ ] 监控验证码出现频率
- [ ] 注意Downloads文件夹的文件数量
- [ ] 每批次后暂停适当时间

### 完成后检查
- [ ] 运行`move_recent_pdfs.py`移动文件
- [ ] 运行`check_all_progress.py`验证进度
- [ ] 对比预期数量与实际数量
- [ ] 更新TODO列表

---

## 📞 需要帮助时

### 问题诊断流程

```
1. 先检查是否是已知问题
   → 查看"常见问题解决"章节

2. 检查环境是否正常
   → Chrome连接: list_pages
   → Python环境: python --version
   → 文件路径: ls "目标文件夹"

3. 查看详细错误信息
   → 截图错误提示
   → 复制完整的错误堆栈

4. 对照操作流程
   → 确认是否遗漏了某个步骤
   → 确认参数是否正确

5. 寻求帮助
   → 提供详细的问题描述
   → 包含错误信息和截图
   → 说明已经尝试过的解决方法
```

### 提问模板

```
【问题描述】
我在执行XXX步骤时遇到了XXX问题

【当前状态】
- 已完成：XXX
- 正在执行：XXX
- 错误信息：XXX

【已尝试的解决方法】
1. XXX
2. XXX

【期望结果】
希望能够XXX
```

---

## 🎓 总结

### 核心优势
- ✅ **自动化程度高**: 90%的操作可以自动完成
- ✅ **可靠性强**: 经过实战验证的流程
- ✅ **易于复用**: 详细的文档和代码模板
- ✅ **灵活应对**: 多种场景的解决方案

### 成功关键
1. **分批次处理**: 避免触发频率限制
2. **充分延时**: 给系统足够的响应时间
3. **实时检查**: 随时了解完成进度
4. **备份重要数据**: 定期保存进度

### 未来改进
- [ ] 实现自动验证码识别
- [ ] 开发GUI界面
- [ ] 添加断点续传功能
- [ ] 支持更多数据库

---

**最后更新**: 2025-10-19  
**文档维护**: 根据实际使用情况持续更新

**祝你下载顺利！** 🎉

